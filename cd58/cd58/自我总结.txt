好的方面:
    1. 通过这次爬取，我学习到了如何通过 chrome 开发者工具调试 js，从而破解 加密参数的构造方法;
    2. 爬取网页之前，可以尝试删除一些复杂的参数，让网页更加简单，前提是删除参数之后，能正常访问
坏的方面：
    1. 遇到难题，不要一直死磕，多查阅文献，资料，多 sou;
    2. 学会换一个角度想问题

新知识：
    1. Redirect(302) 表示重定向，意思是从当前网页重新转向另一个网页，这个网页可以是 404 提示网页、
   防火墙网页、当然也可以是 职位招聘网页，关键看重新定向到那个网页去;
    2. 为什么有时候数据有很多重复的？ 原因是当你调式程序时，你开启了 scrapy 自动缓存的设置，加上你没
   有在 scrapy shell 中进行调试，当你直接 scrapy crawl 时，你已经爬取了相当多的重复网页。所以，吸取教训
   进行代码调式时，应尽量使用 scrapy 自带的 scrapy_shell调试。
    3. scrapy_redis 自带的 过滤器是牺牲内存代价，换来的时间，当你爬取量级达到 亿级，会占用 120 GB，
   当然，内存多少也取决于 爬取字段的大小多少。所以，应该尽可能的使用 bloomfilter，该过滤器占用内存极少，
   且数据丢失率很低
    4. 对于 分布式爬虫，我个人电脑的伪分布式大概可以开个 20 几个，想象一下，你有 8 台电脑，每台电脑都能
   开 20 几个，一个伪分布式平均能爬 5个/s， 那么这个就相当于 每秒 5*20*8=800 ,每秒800个数据。

